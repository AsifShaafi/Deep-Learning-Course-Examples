{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ProfessorDong/Deep-Learning-Course-Examples/blob/master/ML_Examples/ClassifyCIFAR10_PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cmvqmcAuXzUx"
      },
      "source": [
        "Import necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "KbX2pHcvX5ZD"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_OQ6ypRX7Wn"
      },
      "source": [
        "Define hyperparameters and data transformation pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "vINF2t15X_M_"
      },
      "outputs": [],
      "source": [
        "# Define hyperparameters\n",
        "num_epochs = 10\n",
        "batch_size = 64\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Define the data transformation pipeline\n",
        "transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xX0XW7ZnYSdk"
      },
      "source": [
        "Load the CIFAR-10 image dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qudH6-SvYWan",
        "outputId": "fa5d17bb-ecb3-4f43-c35c-2e7b59bb460f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100.0%\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "# Load the CIFAR-10 dataset\n",
        "train_dataset = datasets.CIFAR10(root='./data', train=True, transform=transform, download=True)\n",
        "test_dataset = datasets.CIFAR10(root='./data', train=False, transform=transform, download=True)\n",
        "\n",
        "# Create data loaders for batch processing\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fakiV1gOYjZ0"
      },
      "source": [
        "Define the CNN neural network architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "dQRiGNvSYi0n"
      },
      "outputs": [],
      "source": [
        "# Define the neural network architecture\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.fc1 = nn.Linear(128 * 8 * 8, 512)\n",
        "        self.fc2 = nn.Linear(512, 10)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = nn.functional.relu(self.conv1(x))\n",
        "        x = nn.functional.relu(self.conv2(x))\n",
        "        x = nn.functional.max_pool2d(x, 2)\n",
        "        x = nn.functional.relu(self.conv3(x))\n",
        "        x = nn.functional.max_pool2d(x, 2)\n",
        "        x = x.view(-1, 128 * 8 * 8)\n",
        "        x = nn.functional.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6HUsxZGYq74"
      },
      "source": [
        "Create an instance of the neural network and define the loss function and optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bGTP6mChYtmP",
        "outputId": "67d86d6b-25ff-47b3-b9e1-4591174b16ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (fc1): Linear(in_features=8192, out_features=512, bias=True)\n",
            "  (fc2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# Create an instance of the neural network and define the loss function and optimizer\n",
        "net = Net()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
        "\n",
        "print(net)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C04jVEgiYy1y"
      },
      "source": [
        "Train the neural network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5N6crcBXY1gH",
        "outputId": "21b563a4-34e2-4867-dd9c-5b7142254d73"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Step [100/782], Loss: 1.8844\n",
            "Epoch [1/10], Step [200/782], Loss: 1.7509\n",
            "Epoch [1/10], Step [300/782], Loss: 1.5877\n",
            "Epoch [1/10], Step [400/782], Loss: 1.5527\n",
            "Epoch [1/10], Step [500/782], Loss: 1.3309\n",
            "Epoch [1/10], Step [600/782], Loss: 1.6355\n",
            "Epoch [1/10], Step [700/782], Loss: 1.4911\n",
            "Epoch [2/10], Step [100/782], Loss: 1.3594\n",
            "Epoch [2/10], Step [200/782], Loss: 1.0729\n",
            "Epoch [2/10], Step [300/782], Loss: 1.3262\n",
            "Epoch [2/10], Step [400/782], Loss: 1.0474\n",
            "Epoch [2/10], Step [500/782], Loss: 0.9256\n",
            "Epoch [2/10], Step [600/782], Loss: 1.1332\n",
            "Epoch [2/10], Step [700/782], Loss: 1.1914\n",
            "Epoch [3/10], Step [100/782], Loss: 1.0226\n",
            "Epoch [3/10], Step [200/782], Loss: 0.9879\n",
            "Epoch [3/10], Step [300/782], Loss: 0.9356\n",
            "Epoch [3/10], Step [400/782], Loss: 0.9315\n",
            "Epoch [3/10], Step [500/782], Loss: 0.7401\n",
            "Epoch [3/10], Step [600/782], Loss: 1.0841\n",
            "Epoch [3/10], Step [700/782], Loss: 0.9822\n",
            "Epoch [4/10], Step [100/782], Loss: 0.8510\n",
            "Epoch [4/10], Step [200/782], Loss: 0.9004\n",
            "Epoch [4/10], Step [300/782], Loss: 1.1319\n",
            "Epoch [4/10], Step [400/782], Loss: 0.8371\n",
            "Epoch [4/10], Step [500/782], Loss: 0.6863\n",
            "Epoch [4/10], Step [600/782], Loss: 0.9486\n",
            "Epoch [4/10], Step [700/782], Loss: 0.7423\n",
            "Epoch [5/10], Step [100/782], Loss: 0.8757\n",
            "Epoch [5/10], Step [200/782], Loss: 0.7184\n",
            "Epoch [5/10], Step [300/782], Loss: 1.1549\n",
            "Epoch [5/10], Step [400/782], Loss: 0.6547\n",
            "Epoch [5/10], Step [500/782], Loss: 0.8992\n",
            "Epoch [5/10], Step [600/782], Loss: 0.8710\n",
            "Epoch [5/10], Step [700/782], Loss: 0.7945\n",
            "Epoch [6/10], Step [100/782], Loss: 0.7221\n",
            "Epoch [6/10], Step [200/782], Loss: 0.9974\n",
            "Epoch [6/10], Step [300/782], Loss: 0.8442\n",
            "Epoch [6/10], Step [400/782], Loss: 1.3830\n",
            "Epoch [6/10], Step [500/782], Loss: 0.9194\n",
            "Epoch [6/10], Step [600/782], Loss: 0.8076\n",
            "Epoch [6/10], Step [700/782], Loss: 0.7872\n",
            "Epoch [7/10], Step [100/782], Loss: 0.7221\n",
            "Epoch [7/10], Step [200/782], Loss: 0.9430\n",
            "Epoch [7/10], Step [300/782], Loss: 0.9833\n",
            "Epoch [7/10], Step [400/782], Loss: 0.8884\n",
            "Epoch [7/10], Step [500/782], Loss: 0.8007\n",
            "Epoch [7/10], Step [600/782], Loss: 0.6830\n",
            "Epoch [7/10], Step [700/782], Loss: 0.8365\n",
            "Epoch [8/10], Step [100/782], Loss: 0.6941\n",
            "Epoch [8/10], Step [200/782], Loss: 0.8441\n",
            "Epoch [8/10], Step [300/782], Loss: 0.6187\n",
            "Epoch [8/10], Step [400/782], Loss: 0.6254\n",
            "Epoch [8/10], Step [500/782], Loss: 0.6625\n",
            "Epoch [8/10], Step [600/782], Loss: 1.0421\n",
            "Epoch [8/10], Step [700/782], Loss: 0.6832\n",
            "Epoch [9/10], Step [100/782], Loss: 0.5457\n",
            "Epoch [9/10], Step [200/782], Loss: 0.8496\n",
            "Epoch [9/10], Step [300/782], Loss: 0.6936\n",
            "Epoch [9/10], Step [400/782], Loss: 0.6894\n",
            "Epoch [9/10], Step [500/782], Loss: 0.7219\n",
            "Epoch [9/10], Step [600/782], Loss: 0.8795\n",
            "Epoch [9/10], Step [700/782], Loss: 0.6750\n",
            "Epoch [10/10], Step [100/782], Loss: 0.4139\n",
            "Epoch [10/10], Step [200/782], Loss: 0.7298\n",
            "Epoch [10/10], Step [300/782], Loss: 0.8353\n",
            "Epoch [10/10], Step [400/782], Loss: 0.6435\n",
            "Epoch [10/10], Step [500/782], Loss: 0.7448\n",
            "Epoch [10/10], Step [600/782], Loss: 0.6107\n",
            "Epoch [10/10], Step [700/782], Loss: 0.7186\n"
          ]
        }
      ],
      "source": [
        "# Train the neural network\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        # Forward pass\n",
        "        outputs = net(images)\n",
        "        # print(images.shape)\n",
        "        # print(outputs.shape)\n",
        "        # print(labels.shape)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (i+1) % 100 == 0:\n",
        "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, i+1, len(train_loader), loss.item()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0CNfg_kZII4"
      },
      "source": [
        "Test the neural network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bx7lzDRjWlTK",
        "outputId": "a932ed85-2b7f-4fbe-961c-d2a267c95991"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 73.49 %\n"
          ]
        }
      ],
      "source": [
        "# Test the neural network\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct / total))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyM/OYD5mGLFh74vtmM5+vYN",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
