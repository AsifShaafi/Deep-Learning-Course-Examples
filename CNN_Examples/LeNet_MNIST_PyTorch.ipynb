{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNnu+JKMPp55JtYyRe8k6iT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ProfessorDong/Deep-Learning-Course-Examples/blob/master/CNN_Examples/LeNet_MNIST_PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Implement the LeNet architecture for classification of MNIST data using PyTorch. \n",
        "\n",
        "1. Define the device to use for training. If a GPU is available, the code will use it for faster computation.\n",
        "\n",
        "2. Define the data transformations to use for the MNIST dataset, including resizing the images to 32x32, converting them to tensors, and normalizing the pixel values to the range [-1, 1].\n",
        "\n",
        "3. Load the MNIST dataset using the `datasets.MNIST` class and the data loaders using the `DataLoader` class.\n",
        "\n",
        "4. Define the LeNet model architecture using the `nn.Module` class and the convolutional, max pooling, and fully connected layers using the `nn.Conv2d`, `nn.MaxPool2d`, and `nn.Linear` classes.\n",
        "\n",
        "5. Create an instance of the model and move it to the device using the `to()` method.\n",
        "\n",
        "6. Define the loss function and optimizer to use during training using the `nn.CrossEntropyLoss` and `optim.SGD` classes.\n",
        "\n",
        "7. Train the model using a loop over the data loader and the `forward()` and `backward()` methods of the model, followed by an optimization step using the `step()` method of the optimizer.\n",
        "\n",
        "8. Evaluate the model on the test set using a loop over the data loader and the `forward()` method of the model, followed by comparing the predicted labels to the true labels and computing the test accuracy.\n"
      ],
      "metadata": {
        "id": "l6fcLH_Dkano"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms"
      ],
      "metadata": {
        "id": "E3b37R_9LvZd"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the device to use for training\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "l4UjZ2hgLzAv"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the data transformations to use for the MNIST dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((32, 32)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])"
      ],
      "metadata": {
        "id": "WHk0lJ2jL4hl"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the MNIST dataset\n",
        "trainset = datasets.MNIST(root='./data', train=True,\n",
        "                          download=True, transform=transform)\n",
        "testset = datasets.MNIST(root='./data', train=False,\n",
        "                         download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=128,\n",
        "                                         shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "id": "J6_bPCQOL8vL"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the LeNet model architecture\n",
        "class LeNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 6, kernel_size=5)\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool1(self.relu(self.conv1(x)))\n",
        "        x = self.pool2(self.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "cPBgybKFMB0y"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an instance of the model and move it to the device\n",
        "net = LeNet().to(device)"
      ],
      "metadata": {
        "id": "tIotNvNFMG2L"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the loss function and optimizer to use during training\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)"
      ],
      "metadata": {
        "id": "oqFTQojPMI8L"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "for epoch in range(10):\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        if i % 200 == 199:\n",
        "            print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 200))\n",
        "            running_loss = 0.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RtjCFlQyMMj8",
        "outputId": "544ebf7d-2979-4e9d-b626-feb428072e87"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,   200] loss: 1.261\n",
            "[1,   400] loss: 0.180\n",
            "[2,   200] loss: 0.107\n",
            "[2,   400] loss: 0.094\n",
            "[3,   200] loss: 0.064\n",
            "[3,   400] loss: 0.068\n",
            "[4,   200] loss: 0.051\n",
            "[4,   400] loss: 0.048\n",
            "[5,   200] loss: 0.042\n",
            "[5,   400] loss: 0.040\n",
            "[6,   200] loss: 0.033\n",
            "[6,   400] loss: 0.037\n",
            "[7,   200] loss: 0.031\n",
            "[7,   400] loss: 0.030\n",
            "[8,   200] loss: 0.025\n",
            "[8,   400] loss: 0.027\n",
            "[9,   200] loss: 0.020\n",
            "[9,   400] loss: 0.025\n",
            "[10,   200] loss: 0.019\n",
            "[10,   400] loss: 0.021\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test set\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data[0].to(device), data[1].to(device)\n",
        "        # display(images.shape)\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Test accuracy: %.2f%%' % (100 * correct/total))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SzZvRjShNygf",
        "outputId": "dcb97e36-76bf-4b2c-9e55-ec51f4f4be3e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 98.97%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Show the model summary\n",
        "from torchsummary import summary\n",
        "\n",
        "summary(net, input_size=(1, 32, 32))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jsz8YkdjPJZ0",
        "outputId": "65522893-53ad-47df-8277-c688393bb826"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1            [-1, 6, 28, 28]             156\n",
            "              ReLU-2            [-1, 6, 28, 28]               0\n",
            "         MaxPool2d-3            [-1, 6, 14, 14]               0\n",
            "            Conv2d-4           [-1, 16, 10, 10]           2,416\n",
            "              ReLU-5           [-1, 16, 10, 10]               0\n",
            "         MaxPool2d-6             [-1, 16, 5, 5]               0\n",
            "            Linear-7                  [-1, 120]          48,120\n",
            "              ReLU-8                  [-1, 120]               0\n",
            "            Linear-9                   [-1, 84]          10,164\n",
            "             ReLU-10                   [-1, 84]               0\n",
            "           Linear-11                   [-1, 10]             850\n",
            "================================================================\n",
            "Total params: 61,706\n",
            "Trainable params: 61,706\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.11\n",
            "Params size (MB): 0.24\n",
            "Estimated Total Size (MB): 0.35\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}